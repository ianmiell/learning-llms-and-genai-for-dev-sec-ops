{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the costs we can consider caching the results of the llm.\n",
    "Langchain allows us to do global caching of calls.\n",
    "You need to verify that the caching does not contain personalized answers that should not be cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (0.0.281)\n",
      "Requirement already satisfied: openai in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (0.28.0)\n",
      "Collecting gptcache\n",
      "  Obtaining dependency information for gptcache from https://files.pythonhosted.org/packages/3d/b2/08e81ec8d1c851a8ccbcec598100920c34f89963c5004a8cb6662a630df0/gptcache-0.1.40-py3-none-any.whl.metadata\n",
      "  Downloading gptcache-0.1.40-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (0.0.33)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: tqdm in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Collecting cachetools (from gptcache)\n",
      "  Obtaining dependency information for cachetools from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading gptcache-0.1.40-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.5/124.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: cachetools, gptcache\n",
      "Successfully installed cachetools-5.3.1 gptcache-0.1.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai gptcache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first strategy we enable the caching on a global level.\n",
    "We use a database to store the input prompt and output prompt.\n",
    "And when we get another request that is the same , we return it from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to install package: redis\n",
      "successfully installed package: redis\n",
      "start to install package: redis_om\n",
      "successfully installed package: redis_om\n"
     ]
    }
   ],
   "source": [
    "from gptcache import Cache\n",
    "from gptcache.manager.factory import manager_factory\n",
    "from gptcache.processor.pre import get_prompt\n",
    "from gptcache.adapter.api import init_similar_cache\n",
    "\n",
    "from langchain.cache import GPTCache\n",
    "import langchain\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def get_hashed_name(name):\n",
    "    return hashlib.sha256(name.encode()).hexdigest()\n",
    "\n",
    "\n",
    "def init_gptcache_exact_match(cache_obj: Cache, llm: str):\n",
    "    hashed_llm = get_hashed_name(llm)\n",
    "    cache_obj.init(\n",
    "        pre_embedding_func=get_prompt,\n",
    "        data_manager=manager_factory(manager=\"map\", data_dir=f\"map_cache_{hashed_llm}\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def init_gptcache_embeddings_match(cache_obj: Cache, llm: str):\n",
    "    hashed_llm = get_hashed_name(llm)\n",
    "    init_similar_cache(cache_obj=cache_obj, data_dir=f\"similar_cache_{hashed_llm}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the same prompt 10 times is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import OpenAI\n",
    "llm=OpenAI(temperature=0)\n",
    "prompt=\"Hello world\"\n",
    "\n",
    "langchain.llm_cache=None\n",
    "for i in range(1,10):\n",
    "    result = llm.invoke(prompt)\n",
    "   # print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we enable the caching it goes a lot faster once it's warmed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache = GPTCache(init_gptcache_exact_match)\n",
    "# Now run it once\n",
    "result = llm(\"Hello world\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now run it 10 times\n",
    "for i in range(1,10):\n",
    "    result = llm(prompt)\n",
    "    #print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With embeddings we can make this is a bit more clever. Not just exact matches can be used to return, but now also make it return similar questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to install package: transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/home-ssd/patrick/Library/Caches/pypoetry/virtualenvs/london-devops-2Fa23Xyl-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully installed package: transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 465/465 [00:00<00:00, 1.80MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 827/827 [00:00<00:00, 4.81MB/s]\n",
      "Downloading spiece.model: 100%|██████████| 760k/760k [00:00<00:00, 7.96MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.31M/1.31M [00:00<00:00, 13.0MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 245/245 [00:00<00:00, 942kB/s]\n",
      "Downloading model.onnx: 100%|██████████| 46.9M/46.9M [00:00<00:00, 85.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to install package: faiss-cpu\n",
      "successfully installed package: faiss-cpu\n"
     ]
    }
   ],
   "source": [
    "# Set the caching to use embeddings\n",
    "langchain.llm_cache = GPTCache(init_gptcache_embeddings_match)\n",
    "\n",
    "# Now run it once to warm up the cache\n",
    "result = llm(\"Hello world\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run a similar request\n",
    "similar_prompt=\"Hello world :)\"\n",
    "for i in range(1,10):\n",
    "    result = llm(similar_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "london-devops-VW7lFx7f-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
